{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on CIFAR and ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# check whether run in Colab\n",
    "root = \".\"\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Colab.\")\n",
    "    !pip3 install matplotlib\n",
    "    !pip3 install einops==0.3.0\n",
    "    !pip3 install timm==0.4.9\n",
    "    !git clone https://github.com/xxxnell/how-do-vits-work.git\n",
    "    root = \"./how-do-vits-work\"\n",
    "    sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import models\n",
    "import ops.trains as trains\n",
    "import ops.tests as tests\n",
    "import ops.datasets as datasets\n",
    "import ops.schedulers as schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'name': 'cifar10', 'root': '../data', 'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201], 'padding': 4, 'color_jitter': 0.0, 'auto_augment': 'rand-m9-n2-mstd1.0', 're_prob': 0.0}, 'train': {'warmup_epochs': 5, 'epochs': 300, 'batch_size': 96, 'max_norm': 5, 'smoothing': 0.1, 'mixup': {'num_classes': 10, 'mixup_alpha': 1.0, 'cutmix_alpha': 0.8, 'prob': 1.0}}, 'val': {'batch_size': 256, 'n_ff': 1}, 'model': {'stem': False, 'block': {'image_size': 32, 'patch_size': 2, 'sd': 0.1}}, 'optim': {'name': 'AdamW', 'lr': 0.000125, 'weight_decay': 0.05, 'scheduler': {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 0}}, 'env': {}}\n"
     ]
    }
   ],
   "source": [
    "# config_path = \"%s/configs/cifar10_vit.yaml\" % root\n",
    "config_path = \"%s/configs/cifar10_vit.yaml\" % root\n",
    "# config_path = \"%s/configs/imagenet_vit.yaml\" % root\n",
    "\n",
    "with open(config_path) as f:\n",
    "    args = yaml.safe_load(f)\n",
    "    print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_args = copy.deepcopy(args).get(\"dataset\")\n",
    "train_args = copy.deepcopy(args).get(\"train\")\n",
    "val_args = copy.deepcopy(args).get(\"val\")\n",
    "model_args = copy.deepcopy(args).get(\"model\")\n",
    "optim_args = copy.deepcopy(args).get(\"optim\")\n",
    "env_args = copy.deepcopy(args).get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args['epochs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train: 50000, Test: 10000, Classes: 10\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_test = datasets.get_dataset(**dataset_args, download=True)\n",
    "dataset_name = dataset_args[\"name\"]\n",
    "num_classes = len(dataset_train.classes)\n",
    "\n",
    "dataset_train = DataLoader(dataset_train, \n",
    "                           shuffle=True, \n",
    "                           num_workers=train_args.get(\"num_workers\", 4), \n",
    "                           batch_size=train_args.get(\"batch_size\", 128))\n",
    "dataset_test = DataLoader(dataset_test, \n",
    "                          num_workers=val_args.get(\"num_workers\", 4), \n",
    "                          batch_size=val_args.get(\"batch_size\", 128))\n",
    "\n",
    "print(\"Train: %s, Test: %s, Classes: %s\" % (\n",
    "    len(dataset_train.dataset), \n",
    "    len(dataset_test.dataset), \n",
    "    num_classes\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use provided models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute 'is_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# name = \"vit_s\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m vit_kwargs \u001b[39m=\u001b[39m {  \u001b[39m# for CIFAR\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mimage_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m32\u001b[39m, \n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpatch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mget_model(name, num_classes\u001b[39m=\u001b[39;49mnum_classes, \n\u001b[1;32m     15\u001b[0m                          stem\u001b[39m=\u001b[39;49mmodel_args\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mvit_kwargs)\n\u001b[1;32m     16\u001b[0m \u001b[39m# models.load(model, dataset_name, uid=current_time)\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/wext/msc_studies/monodepth_project/related_work/how-do-vits-work/models/__init__.py:336\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(name, num_classes, stem, verbose, **block_kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mimage_size\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m block_kwargs:\n\u001b[1;32m    335\u001b[0m     image_size \u001b[39m=\u001b[39m block_kwargs[\u001b[39m\"\u001b[39m\u001b[39mimage_size\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 336\u001b[0m     stats(model, torch\u001b[39m.\u001b[39;49mrandn([\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m, image_size, image_size]))\n\u001b[1;32m    337\u001b[0m \u001b[39melif\u001b[39;00m verbose \u001b[39mand\u001b[39;00m stem:\n\u001b[1;32m    338\u001b[0m     stats(model, torch\u001b[39m.\u001b[39mrandn([\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m]))\n",
      "File \u001b[0;32m/mnt/wext/msc_studies/monodepth_project/related_work/how-do-vits-work/models/__init__.py:398\u001b[0m, in \u001b[0;36mstats\u001b[0;34m(model, xs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m xs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 398\u001b[0m     ys \u001b[39m=\u001b[39m model(xs)\n\u001b[1;32m    399\u001b[0m     stat_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, output: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mlist\u001b[39m(ys\u001b[39m.\u001b[39msize())\n\u001b[1;32m    400\u001b[0m \u001b[39mprint\u001b[39m(stat_str)\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/wext/msc_studies/monodepth_project/related_work/how-do-vits-work/models/vit.py:44\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 44\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[1;32m     45\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers(x)\n\u001b[1;32m     46\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/wext/msc_studies/monodepth_project/related_work/how-do-vits-work/models/embeddings.py:26\u001b[0m, in \u001b[0;36mPatchEmbedding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpatch_embedding(x)\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/einops/layers/torch.py:11\u001b[0m, in \u001b[0;36mRearrange.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_recipe(\u001b[39minput\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/einops/layers/__init__.py:41\u001b[0m, in \u001b[0;36mRearrangeMixin._apply_recipe\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply_recipe\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     40\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrecipe()\u001b[39m.\u001b[39;49mapply(x)\n\u001b[1;32m     42\u001b[0m     \u001b[39mexcept\u001b[39;00m EinopsError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     43\u001b[0m         \u001b[39mraise\u001b[39;00m EinopsError(\u001b[39m'\u001b[39m\u001b[39m Error while computing \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m, e))\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/einops/einops.py:203\u001b[0m, in \u001b[0;36mTransformRecipe.apply\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, tensor):\n\u001b[0;32m--> 203\u001b[0m     backend \u001b[39m=\u001b[39m get_backend(tensor)\n\u001b[1;32m    204\u001b[0m     init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstruct_from_shape(\n\u001b[1;32m    205\u001b[0m         backend\u001b[39m.\u001b[39mshape(tensor))\n\u001b[1;32m    206\u001b[0m     tensor \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mreshape(tensor, init_shapes)\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/einops/_backends.py:49\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     47\u001b[0m             backend \u001b[39m=\u001b[39m BackendSubclass()\n\u001b[1;32m     48\u001b[0m             _backends[backend\u001b[39m.\u001b[39mframework_name] \u001b[39m=\u001b[39m backend\n\u001b[0;32m---> 49\u001b[0m             \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39;49mis_appropriate_type(tensor):\n\u001b[1;32m     50\u001b[0m                 \u001b[39mreturn\u001b[39;00m backend\n\u001b[1;32m     52\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mTensor type unknown to einops \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(tensor)))\n",
      "File \u001b[0;32m~/.conda/envs/sc/lib/python3.9/site-packages/einops/_backends.py:513\u001b[0m, in \u001b[0;36mKerasBackend.is_appropriate_type\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_appropriate_type\u001b[39m(\u001b[39mself\u001b[39m, tensor):\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK\u001b[39m.\u001b[39;49mis_tensor(tensor) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK\u001b[39m.\u001b[39mis_keras_tensor(tensor)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute 'is_tensor'"
     ]
    }
   ],
   "source": [
    "# ResNet\n",
    "# name = \"resnet_dnn_50\"\n",
    "# name = \"resnet_dnn_101\"\n",
    "\n",
    "# ViT\n",
    "name = \"vit_ti\"\n",
    "# name = \"vit_s\"\n",
    "\n",
    "vit_kwargs = {  # for CIFAR\n",
    "    \"image_size\": 32, \n",
    "    \"patch_size\": 2,\n",
    "}\n",
    "\n",
    "model = models.get_model(name, num_classes=num_classes, \n",
    "                         stem=model_args.get(\"stem\", False), **vit_kwargs)\n",
    "# models.load(model, dataset_name, uid=current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use `timm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: vit_ti , params: 5.4M\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "model = timm.models.vision_transformer.VisionTransformer(\n",
    "    img_size=32, patch_size=2, num_classes=num_classes,  # for CIFAR\n",
    "    embed_dim=192, depth=12, num_heads=3, qkv_bias=False,  # ViT-Ti\n",
    ")\n",
    "model.name = \"vit_ti\"\n",
    "models.stats(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize the given `moodel` by splitting the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model.name\n",
    "model = nn.DataParallel(model)\n",
    "model.name = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a TensorBoard writer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create TensorBoard log dir:  runs/cifar10/vit_ti/20230806_174610\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = os.path.join(\"runs\", dataset_name, model.name, current_time)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "with open(\"%s/config.yaml\" % log_dir, \"w\") as f:\n",
    "    yaml.dump(args, f)\n",
    "with open(\"%s/model.log\" % log_dir, \"w\") as f:\n",
    "    f.write(repr(model))\n",
    "\n",
    "print(\"Create TensorBoard log dir: \", log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123.52 sec/epoch) Warmup epoch: 0, Loss: 2.2404, lr: 2.500e-05\n",
      "NLL: 2.0406, Cutoffs: 0.0 %, 90.0 %, Accs: 25.340 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 13.140 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 80.180 %, Brier: 0.843, ECE: 6.321 %, ECE±: -6.321 %\n",
      "(122.99 sec/epoch) Warmup epoch: 1, Loss: 2.1964, lr: 5.000e-05\n",
      "NLL: 1.9675, Cutoffs: 0.0 %, 90.0 %, Accs: 27.670 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 14.207 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 82.790 %, Brier: 0.824, ECE: 5.975 %, ECE±: -5.975 %\n",
      "(123.55 sec/epoch) Warmup epoch: 2, Loss: 2.1604, lr: 7.500e-05\n",
      "NLL: 1.8647, Cutoffs: 0.0 %, 90.0 %, Accs: 32.510 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 18.140 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 85.630 %, Brier: 0.797, ECE: 7.864 %, ECE±: -7.864 %\n",
      "(123.42 sec/epoch) Warmup epoch: 3, Loss: 2.1186, lr: 1.000e-04\n",
      "NLL: 1.7607, Cutoffs: 0.0 %, 90.0 %, Accs: 39.830 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 24.252 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 88.820 %, Brier: 0.763, ECE: 14.084 %, ECE±: -14.084 %\n",
      "(123.51 sec/epoch) Warmup epoch: 4, Loss: 2.0660, lr: 1.250e-04\n",
      "NLL: 1.5921, Cutoffs: 0.0 %, 90.0 %, Accs: 44.360 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 27.396 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 92.150 %, Brier: 0.708, ECE: 11.929 %, ECE±: -11.929 %\n",
      "The model is warmed up: 656.57 sec \n",
      "\n",
      "(123.49 sec/epoch) Epoch: 0, Loss: 2.0347, lr: 1.250e-04\n",
      "NLL: 1.5733, Cutoffs: 0.0 %, 90.0 %, Accs: 47.420 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 30.278 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 92.050 %, Brier: 0.695, ECE: 15.074 %, ECE±: -15.074 %\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "optimizer, train_scheduler = trains.get_optimizer(model, **optim_args)\n",
    "warmup_scheduler = schedulers.WarmupScheduler(optimizer, len(dataset_train) * train_args.get(\"warmup_epochs\", 0))\n",
    "\n",
    "trains.train(model, optimizer,\n",
    "             dataset_train, dataset_test,\n",
    "             train_scheduler, warmup_scheduler,\n",
    "             train_args, val_args, gpu,\n",
    "             writer, \n",
    "             snapshot=-1, dataset_name=dataset_name, uid=current_time)  # Set `snapshot=N` to save snapshots every N epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save(model, dataset_name, current_time, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 1, NLL: 1.5733, Cutoffs: 0.0 %, 90.0 %, Accs: 47.420 %, 0.000 %, Uncs: 0.000 %, 100.000 %, IoUs: 30.278 %, 0.000 %, Freqs: 100.000 %, 0.000 %, Top-5: 92.050 %, Brier: 0.695, ECE: 15.074 %, ECE±: -15.074 %\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "\n",
    "model = model.cuda() if gpu else model.cpu()\n",
    "metrics_list = []\n",
    "for n_ff in [1]:\n",
    "    print(\"N: %s, \" % n_ff, end=\"\")\n",
    "    *metrics, cal_diag = tests.test(model, n_ff, dataset_test, verbose=False, gpu=gpu)\n",
    "    metrics_list.append([n_ff, *metrics])\n",
    "\n",
    "leaderboard_path = os.path.join(\"leaderboard\", \"logs\", dataset_name, model.name)\n",
    "Path(leaderboard_path).mkdir(parents=True, exist_ok=True)\n",
    "metrics_dir = os.path.join(leaderboard_path, \"%s_%s_%s.csv\" % (dataset_name, model.name, current_time))\n",
    "tests.save_metrics(metrics_dir, metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
